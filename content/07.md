#Threading
##Binaries, Processes, and Threads
Binaries are dormant programs residing on a storage medium, compiled to a format accessible by a given operating system and machine architecture, ready to execute but not yet in motion. Processes are the operating system abstraction representing those binaries in action: the loaded binary, virtualized memory, kernel resources such as open files, an associated user, and so on. Threads are the unit of execution within a process: a virtualized processor, a stack, and program state.
##Multithreading
benefits to multithreading: 

- Programming abstraction. Dividing up work and assigning each division to a unit of execution is a natural approach to many problems.
- Parallelism. In machines with multiple processors, threads provide an efficient way to achieve true parallelism.
- Improving responsiveness. Even on a uniprocessor machine, multithreading can improve a process's responsiveness.
- Blocking I/O. Without threads, blocking I/O halts the entire process.
- Context switching. The cost of switching from one thread to a different thread within the same process is significantly cheaper than process-to-process context switching.
- Memory savings. Threads provide an efficient way to share memory yet utilize multiple units of execution.

###Context switching: Processes Versus Threads
Machine architecture imposes costs to process switching that threads do not bear, as process switching involves swapping out one virtual address space for another. On x86, for example, the translation lookaside buffer(TLB), which is a cache mapping virtual to physical memory addresses, must be flushed when swapping out the virtual address space. TLB misses are incredibly detrimental to system performance. Threads do not bear these costs, as thread-to-thread switching does not swap out the virtual address space.

###Costs of Multithreading
Designing, writing, understanding, and debugging multithreading programs is significantly more difficult than a single-threaded process.

###Alternatives to Multithreading
The latency and I/O benefits to threading are attainable via a combination of multiplexed I/O, nonblocking I/O, and asynchronous I/O. If true parallelism is your goal, N processes can achieve the same processor utilization as N threads, albeit at some cost of increased resource consumption and context switching overhead. Conversely, if memory saving is your goal, Linux provides tools to share memory in a more limited manner than threads.

##Threading Models
###User-Level Threading
This model requires little or no kernel suport but significant user-space code, including a user-space scheduler to manage the threads and a mechanism to catch and handle I/O in a nonblocking fashion. The benefit of user-level threads is that context switch are nearly free, as the application itself can decide what thread to run and when, without involving the kernel. The downside is that, as there is only a single kernel entity backing the N threads, this model cannot utilize multiple processors and thus is unable to provide true parallelism.

###Hybrid Threading
The kernel provides a native thread concept, while user space also implements user threads. User space, perhaps in conjunction with the kernel, then decides how to map N user threads onto M kernel threads, where N>=M. This model is rather complex to implement.

###Coroutines and Fibers
Coroutines and fibers provide a unit of execution even lighter in weight than the thread. They are, like user-level threads, user-space phenomena but unlike user-level threads, there is little or no user-space support for their scheduling and execution. Instead, they are cooperatively scheduled, requiring an explicit yield in one to move to another.

##Threading Patterns
###Thread-per-Connection
Thread-per-connection is a programming pattern in which a unit of work is assigned to one thread, and that thread is assigned at most one unit of work, for the duration of the unit of work's execution.

###Event-Driven Threading
In this model, request processing is converted into a series of asynchronous I/O requests and associated callbacks. These callbacks can be waited on via multiplexed I/O; the process of doing so is called an event loop. When the I/O requests are returned, the event loop hands the callback off to a waiting thread.

##Concurrency, Parallelism, and Races
Concurrency is the ability of two or more threads to execute in overlapping time periods. Parallelism is the ability to execute two or more threads simultaneously. Concurrency is a programming pattern, a way of approaching problems. Parallelism is a hardware feature, achievable through concurrency. Both are useful.

A race condition is a situation in which the unsynchronized access of a shared resource by two or more threads leads to erroneous program behavior.

##Synchronization
###Mutexes
The most common technique is the lock, a mechanism for ensuring mutual exclusion within a critical region, rendering it atomic. Because locks enforce mutual exclusion, they are known in Pthreads as mutexes.

###Deadlocks
A deadlock is a situation in which two threads are waiting for the other to finish, and thus neither does.

####Deadlock avoidance
Avoiding deadlocks is important, and the only consistent, safe way to do is by designing locking into your multithreaded program from day one. It is important to associate mutexes with data, not code, and have a clear hierarchy of data.

##Pthreads
###Linux Threading Implementations
In Linux, the implementation of Pthreads standard is provided by glibc, Linux's C library. Over time, glibc has provided two different implementations of Pthreads: LinuxThreads and NPTL.

LinuxThreads is Linux's original Pthread implementation, providing 1:1 threading. LinuxThreads was designed for a kernel that provided very little support for threading: other than the `clone()` system call to create a new thread, LinuxThreads implemented POSIX threading using existing Unix interfaces. Due to the lack of kernel support for Pthreads, LinuxThreads required a "manager" thread to coordinate activity, scaled poorly to large number of threads, and was imperfect in its comformance to the POSIX standard.

Native POSIX Thread Library(NPTL) provides 1:1 threading based around the `clone()` system call and the kernel's model that threads are just like any process, except that they share certain resources.

###The Pthread API
Pthread functions may be broken into two large groupings:

- Thread management: functions to create, destroy, join, and detach threads.
- Synchronization: functions to manage the synchronization of threads, including mutexes, condition variables, and barriers.

###Creating Threads
```C
#include <pthread.h>

int pthread_create(pthread_t *thread,
					const pthread_attr_t *att,
					void *(*start_routine)(void *),
					void *arg);
```
Thread attributes let programs change many aspects of threads, such as their stack size, schedulizing parameters, and initial detached state.

Similar to `fork()`, the new thread inherits most attributes, capabilities, and state from its parent. Unlike `fork()`, threads share the resources of their parent instead of receiving a copy. The most notable shared resource is, of course, the process address space, but threads also share signal handlers and open files.

###Thread IDs
The thread ID(TID) is the thread analogue to the process ID(PID). While the PID is assigned by the Linux kernel,  the TID is just assigned in the Pthread library. A thread can obtain its TID at runtime via the `pthread_self()` function:

```C
#include <pthread.h>

pthread_t pthread_self(void);
```

####Comparing thread IDs
Because the Pthread standard does not require `pthread_t` to be an arithmetic type, there is no guarantee that the equality operator will work. Consequently, to compare thread IDs, the Pthread library needs to provide a special interface:

```C
#include <pthread.h>

int pthread_equal(pthread_t t1, pthread_t t2);
```

###Terminating Threads
Threads may terminate under several circumstances, all of which have analogues to process termination:

- If a thread returns from its start routine, it terminates. This is akin to "falling off the end" of `main()`.
- If a thread invokes the `pthread_exit` function, it terminates. This is akin to calling `exit()`.
- If the thread is canceled by another thread via the `pthread_cancel` function, it terminates. This is akin to being sent the SIGKILL signal via `kill()`.

####Terminating yourself
```C
#include <pthread.h>

// retval is provided to any thread waiting on the terminating thread's death
void pthread_exit(void *retval);
```

###Terminating others

```C
#include <pthread.h>

int pthread_cancel(pthread_t thread);
```

If and when a thread is cancellable is a bit complicated. A thread's cancellation state is either enabled or disabled. The default for new threads is enabled. If a thread has disabled cancellation, the request is queued until it is enabled. Otherwise, the cancellation type dictates when cancellation occurs. Threads can change their state via `pthread_set_cancelstate()`:

```C
#include <pthread.h>

// state maybe PTHREAD_CANCEL_ENABLE or PTHREAD_CANCEL_DISABLE
int pthread_setcancelstate(int state, int *oldstate);
```

A thread's cancellation type is either asynchronous or deferred, with the latter being the default. Threads can change their type via `pthread_setcanceltype()`:

```C
#include <pthread.h>

// type maybe PTHREAD_CANCEL_ASYNCHRONOUS or PTHREAD_CANCEL_DEFERRED
int pthread_setcanceltype(int type, int *oldtype);
```

###Joining and Detaching Threads
```C
#include <pthread.h>

int pthread_join(pthread_t thread, void **retval);
```
Upon successful invocation, the invoking thread is blocked until the threads specified by thread terminates.

```C
#include <pthread.h>

int pthread_detach(pthread_t thread);
```

By default, threads are created as joinable. Threads may, however, detach, rendering them no longer joinable. Because threads consume system resources until joined, just as processes consume system resources until their parent call `wait()`, threads that you do not intend to join should be detached.

###Pthread Mutexes
####Initializing mutexes
```C
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
```

####Locking mutexes
```C
#include <pthread.h>

int pthread_mutex_lock(pthread_mutex_t *mutex);
```

####Unlocking mutexes
```C
#include <pthread.h>

int pthread_mutex_unlock(pthread_mutex_t *mutex);
```